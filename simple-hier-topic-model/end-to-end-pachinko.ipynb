{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from utils import nice_tree_plot, niceprint, permute_square, invert_permutation\n",
    "from compute_pam import compute_combo_tensor_pam, IndividualNodeAlphaCalc\n",
    "from example_graphs import make_tree\n",
    "from sim_data import PAMSampler, topics_griffiths_steyvers\n",
    "from lda_collapsed_gibbs import CollapsedGibbs\n",
    "from param_stats import topic_difference, find_flat_permutation, find_structural_permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Set up parameters of the model (tree structure, alphas, and topic definitions -- anything else?)\n",
    "2. Compute \"true\" co-occurrence matrix\n",
    "3. Generate some simulated data by sampling from the model\n",
    "  - Parameters: Number of documents, distribution over document sizes\n",
    "4. Compute \"empirical\" co-occurrence matrix (using known per-word-slot topic assignments).  Compare to \"true\" co-occurrence matrix.\n",
    "5. Apply LDA or anchor words to the simulated data -- estimate topics and co-occurrence matrix.  Compare \"estimated\" co-occurrence matrix to \"true\" and \"empirical\" matrices.  Compare \"estimated\" topics to \"true\" topics.\n",
    "  - Parameters: number of topics; any other parameters needed for the chosen topic-estimation algorithm\n",
    "6. Compute ratio matrix\n",
    "7. Derive triplet constraints from ratio matrix\n",
    "8. Apply Aho's algorithm to constraints, producing a tree where each leaf corresponds to a topic.  Compare to \"true\" tree structure.\n",
    "9. Extract alpha parameters from co-occurrence matrix.  Compare to \"true\" alpha parameters.\n",
    "  - Parameters: $\\alpha_{max}$ and $\\delta_{min}$ corresponding to hypothesis class\n",
    "  \n",
    "TODO: Find a way to remove # of topics as a parameter (eg, measure perplexity, and loop over different of # topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
